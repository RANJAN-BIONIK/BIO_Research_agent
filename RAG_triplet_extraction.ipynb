{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc25a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/home/bionik/miniconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_ollama import ChatOllama,OllamaEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "import xml.etree.ElementTree as ET\n",
    "import pyttsx3\n",
    "from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser\n",
    "from typing import List\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import re\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "import numpy as np\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate,SystemMessagePromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import spacy\n",
    "import pickle\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from scispacy.linking import EntityLinker\n",
    "import scispacy\n",
    "import re\n",
    "from langchain.messages import SystemMessage,HumanMessage,AIMessage,ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import pyobo\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from typing import List, Optional, Literal\n",
    "import re\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dbbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linker = pyobo.get_scispacy_entity_linker(\"uniprot\", filter_for_definitions=False, resolve_abbreviations=True)\n",
    "nlp = spacy.load('en_ner_jnlpba_md')\n",
    "nlp.disable_pipes(\"tagger\", \"parser\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "linker = pyobo.get_scispacy_entity_linker(\"hgnc\", filter_for_definitions=False, resolve_abbreviations=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4301cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_query(\n",
    "    include_topics: List[str],\n",
    "    operator: Literal[\"AND\", \"OR\"] = \"AND\",\n",
    "    exclude_topics: Optional[List[str]] = None,\n",
    "    publication_type: Optional[Literal[\"review\", \"article\"]] = None,\n",
    "    organism: Optional[str] = None,\n",
    "    journal: Optional[str] = None,\n",
    "    start_year: Optional[int] = None,\n",
    "    end_year: Optional[int] = None,\n",
    "    free_full_text: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a simple, elegant PubMed query.\n",
    "    \"\"\"\n",
    "\n",
    "    clauses = []\n",
    "\n",
    "    # Automatic free full text\n",
    "    if free_full_text:\n",
    "        clauses.append(\"free full text[filter]\")\n",
    "\n",
    "    # Include topics\n",
    "    if include_topics:\n",
    "        topic_clause = \" OR \".join([f'\"{t}\"[Title/Abstract]' for t in include_topics])\n",
    "        if len(include_topics) > 1:\n",
    "            topic_clause = f'({topic_clause})'\n",
    "        clauses.append(topic_clause)\n",
    "\n",
    "    # Publication type\n",
    "    if publication_type:\n",
    "        pt_map = {\"review\": \"review[Publication Type]\", \"article\": \"journal article[Publication Type]\"}\n",
    "        clauses.append(pt_map.get(publication_type.lower(), \"\"))\n",
    "\n",
    "    # Organism\n",
    "    if organism:\n",
    "        org_map = {\"human\": \"humans[MeSH Terms]\", \"mouse\": \"mice[MeSH Terms]\", \"rat\": \"rats[MeSH Terms]\"}\n",
    "        clauses.append(org_map.get(organism.lower(), f'\"{organism}\"[MeSH Terms]'))\n",
    "\n",
    "    # Journal\n",
    "    if journal:\n",
    "        clauses.append(f'\"{journal}\"[Journal]')\n",
    "\n",
    "    # Date range\n",
    "    if start_year and end_year:\n",
    "        clauses.append(f'(\"{start_year}\"[Date - Publication] : \"{end_year}\"[Date - Publication])')\n",
    "    elif start_year:\n",
    "        clauses.append(f'\"{start_year}\"[Date - Publication]')\n",
    "    elif end_year:\n",
    "        clauses.append(f'\"{end_year}\"[Date - Publication]')\n",
    "\n",
    "    # Exclude topics\n",
    "    if exclude_topics:\n",
    "        for t in exclude_topics:\n",
    "            clauses.append(f'NOT \"{t}\"[Title/Abstract]')\n",
    "\n",
    "    # Combine clauses with AND\n",
    "    return \" AND \".join(clauses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca26079",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pubmed_query(\n",
    "    include_topics=[\"AKT signaling\",'wnt signalling'],\n",
    "    publication_type=\"review\",\n",
    "    organism=\"Human\",\n",
    "    start_year=2020,\n",
    "    end_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fe835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ncbi_data(query):\n",
    "    base_url_esearch='https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    params_esearch = {\"db\": \"pubmed\",\"term\": query,\"retmode\": \"json\",\"retstart\": 0,\"retmax\": 10000,'email':'your_email@example.com',\n",
    "              'datetype':'pdat','mindate':'2010/01/01', 'maxdate':'2025/01/01'}\n",
    "    response_esearch=requests.get(base_url_esearch, params=params_esearch)\n",
    "    list_of_pubmed=response_esearch.json()['esearchresult']['idlist']\n",
    "    dois=[]\n",
    "    journal=[]\n",
    "    base_url_efetch='https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    for list in [list_of_pubmed[i:i+10]for i in range(0,len(list_of_pubmed),10)]:\n",
    "        query=f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "        param_efetch={'retmode':'xml',\"db\": \"pubmed\",\"id\": ','.join(list),\"retstart\": 0,\"retmax\": 1000}\n",
    "        response_efetch=requests.get(base_url_efetch,params=param_efetch)\n",
    "        tree = ET.fromstring(response_efetch.text)\n",
    "        base='https://doi.org/'\n",
    "        for i in tree.findall('PubmedArticle/PubmedData/ArticleIdList/ArticleId'):\n",
    "            if i.attrib.get('IdType')=='doi':\n",
    "                dois.append(base+i.text)\n",
    "        for i in tree.findall('PubmedArticle/MedlineCitation/Article/Journal/Title'):\n",
    "            journal.append(i.text)\n",
    "            \n",
    "    return dois, journal\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c28e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi,jornal=fetch_ncbi_data(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60b3061",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mt]+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_clean_document\u001b[39m(raw_doc: \u001b[43mDocument\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Document:\n\u001b[1;32m     35\u001b[0m     clean_text \u001b[38;5;241m=\u001b[39m extract_main_article_text(raw_doc\u001b[38;5;241m.\u001b[39mpage_content)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Document(\n\u001b[1;32m     38\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mclean_text,\n\u001b[1;32m     39\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         }\n\u001b[1;32m     44\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Document' is not defined"
     ]
    }
   ],
   "source": [
    "def load_doi_page_raw(url: str):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=[url],\n",
    "        header_template={\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (X11; Linux x86_64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/120.0 Safari/537.36\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs[0]\n",
    "\n",
    "def extract_main_article_text(html_text: str) -> str:\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # Remove junk\n",
    "    for tag in soup([\n",
    "        \"script\", \"style\", \"noscript\", \"svg\",\n",
    "        \"header\", \"footer\", \"nav\", \"aside\",\n",
    "        \"form\", \"button\"\n",
    "    ]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def build_clean_document(raw_doc: Document) -> Document:\n",
    "    clean_text = extract_main_article_text(raw_doc.page_content)\n",
    "\n",
    "    return Document(\n",
    "        page_content=clean_text,\n",
    "        metadata={\n",
    "            **raw_doc.metadata,\n",
    "            \"source_type\": \"doi_webpage\",\n",
    "            \"cleaned\": True,\n",
    "        }\n",
    "    )\n",
    "def load_full_article_from_doi(url: str) -> Document:\n",
    "    raw_doc = load_doi_page_raw(url)\n",
    "    clean_doc = build_clean_document(raw_doc)\n",
    "    return clean_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df141d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 201/232 [07:16<01:11,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [08:20<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "}\n",
    "all_docs=[]\n",
    "for i in tqdm(doi): \n",
    "    try:\n",
    "        doc=WebBaseLoader(i,continue_on_failure=True,requests_kwargs={'allow_redirects': True,\n",
    "                                            \"headers\": headers}).load()[0]\n",
    "        if len(doc.page_content)>2000:\n",
    "            all_docs.append(doc)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "}\n",
    "all_docs=[]\n",
    "for i in tqdm(doi): \n",
    "    try:\n",
    "        doc=load_full_article_from_doi(i)\n",
    "        if len(doc.page_content)>1000:\n",
    "            all_docs.append(doc)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b37a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_content(text: str) -> Optional[str]:\n",
    "    \n",
    "    abstract_pat = r'\\babstract\\b'\n",
    "    intro_pat = r'\\bintroduction\\b'\n",
    "    ref_pat = r'\\breference*\\b'\n",
    "    ack_pat = r'\\backnowledgment*\\b'\n",
    "\n",
    "    start_matches = list(re.finditer(intro_pat, text, re.IGNORECASE))\n",
    "    if not start_matches:\n",
    "        start_matches = list(re.finditer(abstract_pat, text, re.IGNORECASE))\n",
    "\n",
    "    end_matches = list(re.finditer(ack_pat, text, re.IGNORECASE))\n",
    "    if not end_matches:\n",
    "        end_matches = list(re.finditer(ref_pat, text, re.IGNORECASE))\n",
    "\n",
    "    if not start_matches or not end_matches:\n",
    "        return None\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    for start in start_matches:\n",
    "        for end in end_matches:\n",
    "            if end.start() > start.start():\n",
    "                span = text[start.start():end.start()].strip()\n",
    "                if len(span) > 300:\n",
    "                    candidates.append(span)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    return max(candidates, key=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c108592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bionik/miniconda3/envs/LLM/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs=[]\n",
    "for doc in all_docs:\n",
    "    text=extract_main_content(doc.page_content)\n",
    "    if text and len(text)>2000:\n",
    "        cleaned_nlp=linker(nlp(text))\n",
    "        new_text=text\n",
    "        for i in reversed(cleaned_nlp.ents):\n",
    "            id=i._.kb_ents\n",
    "            if id:\n",
    "                name=linker.kb.cui_to_entity[id[0][0]].canonical_name\n",
    "                new_text = new_text[:i.start_char] + name + ' ' + i.label_ + new_text[i.end_char:]\n",
    "        doc.page_content=new_text\n",
    "        cleaned_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=700,chunk_overlap=250)\n",
    "chunks=splitter.split_documents(cleaned_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230263d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings_model \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen3-embedding:0.6b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m vectorstore\u001b[38;5;241m=\u001b[39m\u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m retriever\u001b[38;5;241m=\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m,search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:813\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[1;32m    811\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m   1045\u001b[0m         texts,\n\u001b[1;32m   1046\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1051\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain_ollama/embeddings.py:301\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    296\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama client is not initialized. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure Ollama is running and the model is loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/ollama/_client.py:393\u001b[0m, in \u001b[0;36mClient.embed\u001b[0;34m(self, model, input, truncate, options, keep_alive, dimensions)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed\u001b[39m(\n\u001b[1;32m    385\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    386\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m   dimensions: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    392\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EmbedResponse:\n\u001b[0;32m--> 393\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/embed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/ollama/_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/ollama/_client.py:129\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings_model = OllamaEmbeddings(model=\"qwen3-embedding:0.6b\",validate_model_on_init=True)\n",
    "embedding_dim = len(embeddings_model.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"/home/bionik/AI_ML/FDA_Project/LLM/faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252be7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "    \"/home/bionik/AI_ML/FDA_Project/LLM/faiss_index\",\n",
    "    embeddings_model,\n",
    "    allow_dangerous_deserialization=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_model = ChatOllama(num_ctx=10000,model=\"qwen3:4b-instruct-2507-q4_K_M\",validate_model_on_init=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf420f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rewrite_query_tool(query: str, history: str) -> str:\n",
    "    \"\"\"\n",
    "    Rewrite biomedical query for better literature retrieval.\n",
    "    Agent can choose whether to use it.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Rewrite the following biomedical question for literature retrieval.\n",
    "- Preserve meaning exactly.\n",
    "- Use conversation history if helpful.\n",
    "- If already optimal, return unchanged.\n",
    "- Return ONLY the rewritten query.\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Original question:\n",
    "{query}\n",
    "\"\"\"\n",
    "    return LLM_model.invoke(prompt).content.strip()\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Retrieval Middleware\n",
    "# -------------------------------\n",
    "@dynamic_prompt\n",
    "def retrieve_context_middleware(request: ModelRequest) -> str:\n",
    "    \"\"\"\n",
    "    Always retrieves context for all queries from a pre-built vector store.\n",
    "    \"\"\"\n",
    "    user_question = request.state[\"messages\"][-1].content.strip()\n",
    "    history = \"\\n\".join(\n",
    "        m.content for m in request.state[\"messages\"][:-1]\n",
    "        if m.type in {\"human\", \"ai\"}\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # vector_store should be pre-built externally\n",
    "    # -------------------------------\n",
    "    # Example usage:\n",
    "    # docs = vector_store.as_retriever(search_type='mmr', search_kwargs={\"k\":10,\"fetch_k\":20}).get_relevant_documents(user_question)\n",
    "    docs = vector_store.max_marginal_relevance_search(user_question)\n",
    "\n",
    "    # Format sources with citation tags\n",
    "    sources = \"\\n\\n\".join(f\"[SOURCE {i+1} reaserch paper: {d.metadata['source']}]\\n{d.page_content}\" for i, d in enumerate(docs))\n",
    "\n",
    "    # Save in state for dynamic system prompt\n",
    "    request.state[\"retrieved_context\"] = sources\n",
    "    return \"\"  # Middleware doesn't return prompt directly\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Dynamic System Prompt\n",
    "# -------------------------------\n",
    "@dynamic_prompt\n",
    "def rag_system_prompt(request: ModelRequest) -> str:\n",
    "    messages = request.state[\"messages\"]\n",
    "    user_question = messages[-1].content.strip()\n",
    "    context = request.state.get(\"retrieved_context\", \"NO_RELEVANT_SOURCES_FOUND\")\n",
    "    history = \"\\n\".join(\n",
    "        m.content for m in messages[:-1] if m.type in {\"human\", \"ai\"}\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # Query classification\n",
    "    # -----------------------\n",
    "    classify_prompt = f\"\"\"\n",
    "Classify the following biomedical question.\n",
    "\n",
    "Return ONLY one word:\n",
    "FACTUAL  -> asks for known mechanisms or established facts\n",
    "REASONING -> asks about consequences, interventions, or what-if scenarios\n",
    "\n",
    "Question:\n",
    "\"{user_question}\"\n",
    "\"\"\"\n",
    "    qtype = LLM_model.invoke(classify_prompt).content.strip().upper()\n",
    "\n",
    "    # -----------------------\n",
    "    # Mode-specific instructions\n",
    "    # -----------------------\n",
    "    if qtype == \"FACTUAL\":\n",
    "        mode_instruction = \"\"\"\n",
    "FACTUAL MODE (STRICT BUT COMPLETE):\n",
    "\n",
    "- Use retrieved SOURCES as the PRIMARY evidence.\n",
    "- If SOURCES do not fully explain the mechanism, you MAY use\n",
    "  well-established general biomedical knowledge to complete the explanation.\n",
    "- Any such content MUST be explicitly labeled as:\n",
    "\n",
    "  \"General biomedical knowledge (not from retrieved sources):\"\n",
    "\n",
    "- General knowledge MUST:\n",
    "  - be widely accepted textbook-level biology\n",
    "  - not introduce speculation or uncertainty\n",
    "  - not contradict SOURCES\n",
    "\n",
    "- Cite all statements supported by SOURCES as [SOURCE X].\n",
    "\"\"\"\n",
    "    else:  # REASONING\n",
    "        mode_instruction = \"\"\"\n",
    "REASONING MODE:\n",
    "\n",
    "- Use SOURCES to ground all factual statements and cite them as [SOURCE X].\n",
    "- You MAY use general biomedical knowledge when needed; label it clearly.\n",
    "- You MAY propose mechanistic reasoning or hypotheses.\n",
    "- All speculative content MUST be explicitly labeled as:\n",
    "\n",
    "  \"Hypothesis:\"\n",
    "\"\"\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Final system prompt\n",
    "    # -----------------------\n",
    "    return f\"\"\"\n",
    "You are a biomedical research assistant.\n",
    "\n",
    "Global rules:\n",
    "- Prefer retrieved SOURCES over general knowledge.\n",
    "- Never invent citations.\n",
    "- If evidence is insufficient, say so explicitly.\n",
    "- Provide links to all SOURCES at the end of the answer.\n",
    "\n",
    "Question type: {qtype}\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Retrieved SOURCES:\n",
    "{context}\n",
    "\n",
    "{mode_instruction}\n",
    "\n",
    "The agent may use the tool \"rewrite_query_tool\" if it improves retrieval.\n",
    "\n",
    "Produce a clear, structured, citation-grounded answer.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e54ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=LLM_model,\n",
    "    tools=[rewrite_query_tool],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        retrieve_context_middleware,  # always inject retrieved context\n",
    "        rag_system_prompt,            # dynamic prompt\n",
    "        SummarizationMiddleware(\n",
    "            model=LLM_model,\n",
    "            trigger=(\"tokens\", 5000),\n",
    "            keep=(\"messages\", 10),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59983cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"biomed_rag\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How is EGFR signaling activated?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ebe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What happens after that on molecular level??\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what if we RAS protein is mutated in when EGFR pathway is in inactive state?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
